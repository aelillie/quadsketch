\section{Discussion}
\label{discussion}
This section discusses the findings presented in \ref{results}.

\subsection{Verification of Performance}
It should be briefly mentioned that \qs{} performs as expected above the baseline \grid{} implementation on all datasets, and the nature of the graphs behave as can be seen in \cite{wagner17}. The outliers that can be seen in the dataset are the result of running \qs{} and \qsr{} with inappropriate parameters. The accuracy and distortion of the sketch is controlled by \textit{L} and $\Lambda$ which the results confirm as well. 

\subsection{Quadsketch and Quadsketch Random}
Some interesting notions can be discussed from the results. Firstly both algorithms obtain approximately the same best scores for most datasets, except for on \mnist{} where \qsr{} achieves slightly better results. 
Secondly \qsr{} seems to have a better average case than \qs{}. This is quite surprising as the theoretical distince distortion between the points should shift equally much. These performance differences could be explained by the nature of the randomly shifted grid, which in some cases can cause the algorithm to split the points in a favorable manner. What is  specifically beneficial for \qsr{} is the element of randomness that which gives the algorithm a chance to construct more accurate representation of the points within the individual quads of the \qt{}.


\subsection{Threats to validity}

\subsubsection{Randomness}
\label{disc/threats/randomness}
The comparison of the algorithms shown in \ref{results} show single test runs of the algorithms with different sets of parameters. The seemingly positive results for \qsr{} are inherently subdued to some randomness and could wary on further test runs. However the same applies to \qs{} in the randomly shifted grid, which can have effect on the outcome of single runs. \qsr{}'s added layer of randomness facilitates the possibility of both worse and better outcomes than \qs{}.
%\subsubsection{Generated dataset}

\subsubsection{Depth of quad in experiments}
In \cite{wagner17} the experiments on \qs{} and \grid{} runs the parameter $\Lambda$ to 19 and \textit{L} to 20. This project stops the $\Lambda$ at 9 and \textit{L} at 10. The results could possibly disclose more information or differences in the algorithms if not for the earlier cutoff for the parameters in the experiments.

\subsubsection{Missing Dimensionality Reduction}