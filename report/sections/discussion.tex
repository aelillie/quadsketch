\section{Discussion}
\label{discussion}
This section discusses the findings presented in section \ref{results} and evaluates how the results relate to the goals stated in section \ref{intro:problemStatement}. Furthermore possible threats to validity of the results will be discussed.

\subsection{Verification of Performance}
The results in figures \ref{fig:graph sift} and \ref{fig:graph mnist} are used for verifying the results presented in \cite{wagner17}, where results showed that \qs{} outperforms the baseline \grid{} algorithm for the datasets \sift{} and \mnist{} in regards to both accuracy and distortion. In both figures it is clear that \qs{} indeed performs better than \grid{} and therefore confirms this trend. As the precise results in \cite{wagner17} have not been published, no distinct quantitative measure of the ‘similarity’ between the graphs have been used. It is not possible to get a precise reading of each node presented in the original graphs, and as such it is not possible to construct a similarity measure between any two nodes from the original graphs and the graphs created in this paper. 
\\
Apart from these obstacles, it is clear that the graphs are very similar, thus indicating that the results presented in \cite{wagner17} are accurate. It should be mentioned for clarity that outliers on the figures are the result of running \qs{} with inappropriate parameters e.g. there is pruned too much information. This process follows the original in \cite{wagner17}. These outliers help verify that the accuracy and distortion of the sketch is indeed controlled by the parameters \textit{L} and $\Lambda$.  

\subsection{Quadsketch and Quadsketch Random}
This subsection will focus on the comparison between \qs{} and \qsr{} as some interesting notions appear from the results. 
\\
Firstly both algorithms obtain approximately the same best scores for the datasets, except \mnist{} where \qsr{} achieves slightly better results. 
Secondly \qsr{} displays a better average case than \qs{} empirically (figures \ref{fig:graph sift}, \ref{fig:graph mnist} and \ref{fig:graph clust}), which aligns with the expectation from the theoritical improvements behind \qsr{}. The improvements are covered in section \ref{exp:dist}, where the random bit insertion in \qsr{} entails a lower expected distortion of the original pointset in regards to pruned points.
\\
The reason \qsr{} outperforms \qs{} on \mnist{} is due to the large amount of dimensions in the \mnist{} dataset. The more dimensions a dataset contains, the longer the bitstrings being pruned and replaced by quadsketch become. Longer bitstrings being replaced gives the random bit replacement a higher chance of converging towards the expected value. While the expected value grows whith the length of the bitstring, the lower expected value for \qsr{} bit replacement compared to \qs{} gives \qsr{} a better chance to get better accuracy and lower distortion. Even though the final result is data dependent, \qsr{} is likely to bring improvements over \qs{} on arbitrary highly dimensional data or cases where a lot of pruning is going to occur.

\subsection{Threats to validity}

\subsubsection{Randomness}
\label{disc/threats/randomness}
The comparison of the algorithms shown in \ref{results} show single test runs of the algorithms with different sets of parameters. The seemingly positive results for \qsr{} are inherently subdued to some randomness and could vary on further test runs. The same also applies to \qs{} as it makes use a randomly shifted grid, which also can effect on the outcome of single runs. \qsr{}'s added layer of randomness arguably facilitates the possibility of both worse and better outcomes than \qs{}.
%\subsubsection{Generated dataset}

\subsubsection{Depth of quad in experiments}
\label{disc/threats/depth}
In \cite{wagner17} the experiments on \qs{} and \grid{} runs the parameter $\Lambda$ 1 to 19 and \textit{L} 2 to 20. This project stops the $\Lambda$ at 9 and \textit{L} at 10 because the running time of \qs{} with larger parameters becomes infeasibly large for this project. As the results of this paper already discloses both accuracy and distortion values very close to one, the expected improvements gained by increasing the paramenters beyond the current bound are very limited. However it is possible that increasing the parameters would yield results that could disclose more information or other differences in the algorithms.

\subsubsection{Missing Dimensionality Reduction}
There is a slight offset between the results in \cite{wagner17} and the results in this paper. \cite{wagner17} uses Johnson-Lindenstrauss lemma to reduce the number of dimensions in a dataset to be $d=$\bo{$\epsilon^2\log(n)$}. A slight concern arises because it is unclear if the datasets \mnist{} and \sift{} used in this paper has been preprocessed with Johnson-Lindenstrauss. The concern derives from the \qs{} implementation provided on Github, because this implementation does not apply Johnson-Lindenstrauss as part of the source code. Therefore some investigation has been done in this area, and all though not confirmed it seems that the datasets have not undergone any preprocessing. A supportive argument entails that it would be natural to seperate these two processes, as this yields a more clean implementation of \qs{}. 
\\
In the given case that Johnson-Lindenstrauss has not been applied to the datasets, then the offset is natural (and should be expected), as the number of dimensions in a dataset has a direct impact on the number of bits required to represent a point. If this is not the case, then the results obtained in this paper disagrees with the results obtained in \cite{wagner17}. This is however deemed very unlikely. 