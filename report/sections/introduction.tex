\section{Introduction}
\label{introduction}
%Formal introduction goes here
This report investigates and reports on the findings of a relatively new distance-preserving compression algorithm \qs{}, introduced in \cite{wagner17}. This paper is outlined as a project in the course Algorithm Design Project on the second semester of the Software Development MSc program on the IT-University of Copenhagen in the Spring, 2018.
\\
\\
This section describes the motivation behind this project, introduces the project case (i.e. \qs{}), and outlines the overall problem definition. Section \ref{contribution} presents a contribution to the algorithm, being a modified pruning/decompression step. Section \ref{background} describes the research area, presents the \qs{} algorithm, as well as related work. Next, in section \ref{analysis}, an analysis of the algorithm as introduced in \cite{wagner17}, including the \qs{} implementation itself, is carried out. This leads to section \ref{methods}, which explains the methods used for reaching the results given in section \ref{qsr} and \ref{results}. A discussion of the findings is presented in \ref{discussion}, followed by a section with thoughts of future work. Finally a conclusion to the problem definition and the overall project is outlined in \ref{conclusion}.

\subsection{Motivation} %Why are we interested in this?
Compression algorithms for approximate nearest neighbor is a well studied field and many papers have been published on the area. The need for compression arises as many nearest neighbor algorithms suffer from the \textit{"curse of dimensionality"} phenomenon; either space or query time are exponential in the dimension \textit{D}\cite{ilya15}. The \qs{} algorithm is a relatively new contribution to this area, and has a public implementation available\footnote{\url{https://github.com/talwagner/quadsketch/blob/master/src/qs.cpp}}. It is therefore possible to consider both the theory presented in the paper as well as the actual implementation of the algorithm. The motivation for this project has been to make a contribution to the algorithm, either in form of a practical or theoretical improvement, as well as to verify their findings.

\subsection{Case} %What is the QuadSketch paper about?
The report studies the paper, \cite{wagner17}, which presents a distance preserving compression algorithm. The algorithm in its basic form builds a \textit{d}-dimensional \qt{}(also known as a \textit{hyperoctree}) and prunes its edges and nodes to reduce the size of the resulting sketch. The final version divides the dimensions into \textit{blocks} and applies the algorithm to each of them. The compression scheme produces a representation of size \bo{d*$\log$(dB/$\epsilon$) + $\log$(n)} bits per point where \textit{d} is the number of dimensions, \textit{n} the number of points in the dataset, and \textit{B} the number of bits of precision in the coordinates. From this one can approximate distances up to a factor of $1\pm\epsilon$. 

There are two main parameters controlling the performance of \qs{}; \textit{L}, controlling the maximum depth of the \qt{}, and $\Lambda$, controlling the degree of pruning. These parameters directly affects the resulting accuracy and distortion of the algorithm.
\\
\\
The paper introduces several experiments demonstrating the efficiency of the algorithm by conducting nearest-neighbor (NN) searches on different datasets. The authors have tested \qs{} alongside with two other distance preserving compression algorithms, \texttt{Product Quantization} referred to as \pq{} and a baseline scalar uniform quantization implementation referred to as \gr{}. Popular datasets for NN including SIFT and MNIST are used, as well as a "NYC Taxi" dataset and a synthetic "Diagonal" dataset. From the experiments it is concluded that \qs{} overall performs well on "typical" datasets, while its provable guarantees ensure robust performance in a wide range of scenarios\cite[p. 2, l. 38-40]{wagner17}. 

\subsection{Problem statement} %What is our research question?
%From ILO:
%"Plan and carry out a small-scale investigation of an algorithmic research problem. This investigation could be theoretical, experimental, or both."
\cite{wagner17} presents the \qs{} algorithm, competing with state of the art distance preserving compression algorithms, running in \bos{ndL} time and produces a sketch of size \bo{nd$\Lambda$~+~n~log~n} bits\footnote{See Theorem 1 in \cite[p. 3]{wagner17}}. This paper will attempt to verify their results by running similar experiments, as well as on other datasets, and finally propose a contribution the practical performance of the \qs{} algorithm.

%$\Lambda$=\bo{$log(d\;\log\Phi/\epsilon)$}\\

%\ensuremath{L=\log \Phi + \Lambda}

