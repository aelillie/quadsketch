\section{Introduction}
\label{introduction}
%Formal introduction goes here
This report investigates and reports on the findings of the relatively new distance-preserving compression algorithm \qs{}, introduced in \cite{wagner17}. The paper is outlined as a project in the course "Algorithm Design Project" on the second semester of the "Software Development" MSc program on the IT-University of Copenhagen in the Spring, 2018.
\\
\\
This section describes the motivation behind this project, introduces the project case (i.e. \qs{}), and outlines the overall problem definition. Section \ref{contribution} presents the contribution to the algorithm, being the heuristics \dots Section \ref{background} describes the research area, as well as state of the art algorithms, in distance-preserving compression algorithms used for similarity search. Next, in section \ref{analysis}, an analysis of the algorithm as introduced in \cite{wagner17}, including the \qs{} implementation itself, is carried out, investigating the steps taken to build the data structure, the pruning, and the sketch composition. This leads to section \ref{methods}, which explains the methods used for reaching the results given in section \ref{results}. Finally a discussion of the findings is presented in \ref{discussion} and a conclusion to the problem definition and the overall project is outlined in \ref{conclusion}.

\subsection{Motivation} %Why are we interested in this?
Compression algorithms for approximate nearest neighbor is a well studied field and many papers have been published on the area. The need for compression arises as many nearest neighbor algorithm suffer from \textit{"the curse of dimensionality"} phenomenon; either space or query time are exponential in the dimension \textit{D}\cite{ilya15}. That is why it is interesting to investigate an algorithm such as \qs{}, which is so relatively new, and has a public implementation available. %To escape this curse, researchers proposed approximation algorithms for the problem.
%This paper will verify and attempt to improve the results of such an algorithm. 
%TODO: Uddyb med hvorfor det er interessant og hvorfor vi kan vil verificere og improve algorithm?
\subsection{Case} %What is the QuadSketch paper about?
The report studies the paper, \cite{wagner17}, which introduces a distance preserving compression scheme. The key idea is to reduce the number of dimensions \textit{D} by using the Johnson-Lindenstrauss lemma and then make use of a multi-dimensional indexing method known as \textit{hyperoctrees}\footnote{These are referred to as \qt{}'s in the paper} and apply pruning to reduce the size of the resulting sketch. The result of the paper is an algorithm named \qs{}, which represents each point in a Euclidean space using only \bo{d*$\log$(dB/$\epsilon$) + $\log$(n)} where \textit{d} is the result of reducing the number of dimensions \textit{D} of a point set by \bo{$\epsilon^{-2} \log$ n}, \textit{n} is the number of points in the point set, and \textit{B} is the number of bits of precision in the coordinates. Alongside with the paper the authors released an implementation of the algorithm, which is publicly available on Github\footnote{\url{https://github.com/talwagner/quadsketch/blob/master/src/qs.cpp}}. 
\\
\\
The paper introduces several experiments demonstrating the efficiency of the algorithm \qs{}. The authors have tested \qs{} along side with two other distance preserving compression algorithms, \texttt{Product Quantization} referred to as \pq{} and a scalar uniform quantization implementation referred to as \gr{}. These results demonstrate that \qs{} performs well compared to the two other algorithms, even outperforming \pq{} on some of the datasets. 
\\
\\
There are two main parameters controlling the performance of \qs{}. The first one of these is named \textit{L}, and this parameter controls the maximum depth of the \qt{}. The second parameter is named $\Lambda$ and this parameter controls the degree of pruning. The effect these parameters have on the accuracy and average distortion of the algorithm are visible in the paper. These parameters are provided by the user and therefore could reduce the performance of the algorithm if the user is unaware of any optimal values.
\subsection{Problem definition} %What is our research question?
%From ILO:
%"Plan and carry out a small-scale investigation of an algorithmic research problem. This investigation could be theoretical, experimental, or both."
\cite{wagner17} introduces the \qs{} algorithm, which competes with state of the art distance preserving compression algorithms. This paper investigates the performance complexity of \qs{} in terms of the parameters \textit{L} and $\Lambda$ and tries to introduce heuristics for improving or reducing their influence on the complexity. From \tm{2} they are defined as such: \\

$\Lambda$=\bo{$log(d\;\log\Phi/\epsilon)$}\\

\ensuremath{L=\log \Phi + \Lambda}

