\section{Introduction}
\label{introduction}
%Formal introduction goes here
This report investigates and reports on the findings of the relatively new distance-preserving compression algorithm \qs{}, introduced in \cite{wagner17}. This paper is outlined as a project in the course "Algorithm Design Project" on the second semester of the "Software Development" MSc program on the IT-University of Copenhagen in the Spring, 2018.
\\
\\
This section describes the motivation behind this project, introduces the project case (i.e. \qs{}), and outlines the overall problem definition. Section \ref{contribution} presents the contribution to the algorithm, being the heuristics \dots Section \ref{background} describes the research area, as well as state of the art algorithms in distance-preserving compression algorithms used for similarity search. Next, in section \ref{analysis}, an analysis of the algorithm as introduced in \cite{wagner17}, including the \qs{} implementation itself, is carried out, investigating the steps taken to build the data structure, the pruning, and the sketch composition. This leads to section \ref{methods}, which explains the methods used for reaching the results given in section \ref{results}. Finally a discussion of the findings is presented in \ref{discussion} and a conclusion to the problem definition and the overall project is outlined in \ref{conclusion}.

\subsection{Motivation} %Why are we interested in this?
Compression algorithms for approximate nearest neighbor is a well studied field and many papers have been published on the area. The need for compression arises as many nearest neighbor algorithms suffer from the \textit{"curse of dimensionality"} phenomenon; either space or query time are exponential in the dimension \textit{D}\cite{ilya15}. The \qs{} algorithm is a relatively new contribution to this area, and has a public implementation available. It is therefore possible to consider both the theory presented in the paper as well as the actual implementation of the algorithm. %To escape this curse, researchers proposed approximation algorithms for the problem.
%This paper will verify and attempt to improve the results of such an algorithm. 
%TODO: Uddyb med hvorfor det er interessant og hvorfor vi kan vil verificere og improve algorithm?
\subsection{Case} %What is the QuadSketch paper about?
The report studies the paper, \cite{wagner17}, which introduces a distance preserving compression scheme. The key idea is to reduce the number of dimensions \textit{D} by using the Johnson-Lindenstrauss lemma \cite{JohnL} and then make use of a multi-dimensional indexing method known as \textit{hyperoctrees}\footnote{These are referred to as \qt{}'s in the paper} and apply pruning to reduce the size of the resulting sketch. The result of the paper is an algorithm named \qs{}, which represents each point in a Euclidean space using only \bo{d*$\log$(dB/$\epsilon$) + $\log$(n)} where \textit{d} is the result of reducing the number of dimensions \textit{D} of a point set by \bo{$\epsilon^{-2} \log$ n}, \textit{n} is the number of points in the point set, and \textit{B} is the number of bits of precision in the coordinates. Alongside with the paper the authors released an implementation of the algorithm, which is publicly available on Github\footnote{\url{https://github.com/talwagner/quadsketch/blob/master/src/qs.cpp}}. 
\\
\\
The paper introduces several experiments demonstrating the efficiency of the algorithm \qs{}. The authors have tested \qs{} along side with two other distance preserving compression algorithms, \texttt{Product Quantization} referred to as \pq{} and a scalar uniform quantization implementation referred to as \gr{}. These results demonstrate that \qs{} performs well compared to the two other algorithms, even outperforming \pq{} on some of the datasets. 
\\
\\
There are two main parameters controlling the performance of \qs{}. The first one of these is named \textit{L}, and this parameter controls the maximum depth of the \qt{}. The second parameter is named $\Lambda$ and this parameter controls the degree of pruning. The effect these parameters have on the accuracy and average distortion of the algorithm are visible in the paper. These parameters are provided by the user and therefore could reduce the performance of the algorithm if the user is unaware of any optimal values.
\subsection{Problem definition} %What is our research question?
%From ILO:
%"Plan and carry out a small-scale investigation of an algorithmic research problem. This investigation could be theoretical, experimental, or both."
\cite{wagner17} introduces the \qs{} algorithm, which competes with state of the art distance preserving compression algorithms, \qs{} runs in \bos{NdL} time and produces a sketch of size \bo{nd$\Lambda$~+~n~log~n} bits\footnote{See Theorem 1 in \cite{wagner17}}. This paper investigates the validity of the results obtained in \cite{wagner17}, experiments on other datasets and attempts to improve the practical performance of \qs{}.

%$\Lambda$=\bo{$log(d\;\log\Phi/\epsilon)$}\\

%\ensuremath{L=\log \Phi + \Lambda}

